---
title: "Week 9, Day 1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(PPBDS.data)
library(rstanarm)
library(tidyverse)

# We will use the `kenya` dataset from PPBDS.data. This dataset is from Harris,
# Kamindo and Van der Windt (2020): "Electoral Administration in Fledgling
# Democracies:Experimental Evidence from Kenya." The authors worked with
# Kenya's electoral commission in 1,674 communities by assigning polling
# stations to either a control group or to one of five other treatments.

# For simplicity we will only consider polling stations assigned to either
# "control" or to "local". The latter means a treatment in which election
# officials visited the community's polling station for two days, thereby making
# it easier for people to register.

# The outcome variable, `reg_chg`, is the change in voter registration in each
# community. `poverty` is the percentage of the community below the poverty
# level. `distance` is the number of kilometers between the polling station and
# the central political office (where registrations normally take place).
# `pop_density` is a measure of population density around the polling station.


week_9 <- kenya %>% 
  rename(reg_chg = reg_byrv13) %>% 
  filter(treatment %in% c("control", "local")) %>% 
  droplevels() %>% 
  select(reg_chg, treatment, poverty, 
         distance, pop_density)
```


## Scene 1

**Prompt:** In addition to the outcome variable and the treatment, we have 3 statistics for the communities in the sample --- poverty, distance and population density. See code comments above for details. Never hurts to do a little exploratory data analysis. Look at the data!

* Make a scatter plot of `poverty` on the y-axis and `distance` in the x-axis. Include a `geom_smooth()` with `method` set to "lm" and `se` equal to FALSE. Write a sentence to answer these questions:

  + Does poverty cause distance? Or does distance cause poverty? Or both? Or neither?
  + How accurate is the model beyond 90 kilometers?  
  + Eye-balling the chart, how different is the poverty rate between two polling stations whose distance differs by 50 kilometers?
  
* Fit a `stan_glm()` model which relates poverty to distance. Print a summary. (Hint: In order to see the coefficient of `distance`, you will probably need to use the `digits` argument to `print()`.) Interpret the meaning of the two important parameters.  


```{r sc1-a}
week_9 %>% 
  # filter(distance <= 200) %>% 
  ggplot(aes(x = distance, y = poverty)) +
    geom_point() +
    geom_smooth(formula = y ~ x, method = "lm", se = FALSE) +
    labs(title = "Poverty and Distance at Kenyan Polling Stations",
         subtitle = "Poorer communities are further away from registration offices",
         x = "Distance (km)",
         y = "Poverty Measure",
         caption = "Data from Harris, Kamindo and Van der Wind (2020)")
```


```{r sc1-b}
fit_1 <- stan_glm(poverty ~ distance,
                  data = week_9,
                  refresh = 0)

print(fit_1, digits = 4)

0.3863 + 0.0019 * 60

```


**Comments:** Although the first part of chapter 9 covers this material nicely, many/most students will not have read it because the tutorial is not due till Wednesday, because of the exam.

* There are many things to talk about in the plot. With regard to causation, there is no "right" answer. Observations:

  + Always start with potential outcomes and the Rubin Causal Model. If you think that poverty causes distance, then you must be able to imagine at least two possible values for poverty (for a given polling station). Each value of poverty generates a (potentially) different outcome for distance. The causal effect of poverty on distance is the difference between these two potential outcomes.
  + Is that sensible? Maybe! Recall our motto: No causation without manipulation. We could "manipulate" poverty by giving every individual in that community a lot of money. That would change poverty from its current value all the way down to zero. (Recall that poverty is the percentage of the population below a specific value for income.) If that happened, would distance change? Two answers:   
  + No! Distance is fixed. Each polling station is a specified distance from the central registration office. There is only one possible outcome, just like with `age` in Chapter 8.  
  + Yes! If a community got rich enough, the central government would be much more responsive than it currently is. The rich get what they want. If one of those things were a new central registration office nearby, then distance would decrease.

* A model is only as accurate as its data. Since we only have one observation for a polling station which is more than 90 km away, our model is much less likely to be accurate in such cases. We are *extrapolating* far beyond the available evidence. Of course, if we could be certain that the relationship is linear, then our model would be excellent! But we can't be sure of that. And, the less data we have which covers certain values, the less sure we can be of our inferences in those areas.

* Eye-balling, if we were to compare two polling stations with distances which differ by about 50 kilometers, we would expect about a 10% difference in poverty. Key point is that we should use *comparison* language, not causal language. This is observational data, at least until we can make a strong case for considering it as causal.
  
* The interpretations for the intercept and the coefficient of a simple regression with a continuous predictor are not hard, but nor are they simple, especially for students seeing them for the first time. Poverty --- the percentage of the population which is below the poverty level --- is about 39% for polling stations at zero distance from the central registration office. That is what the intercept represents. 

* The coefficient of distance (about 0.002) means that, for two stations which differ by 10 kilometers in their distance to the central registration office, poverty differ by 2% (0.002 x 10 = 0.02). Note how we are avoiding language like "associated with" much less more directly causal stuff like, well. "causes." With observational data, focus on comparisons.  

* The two important parameters are the intercept and the coefficient of distance, obviously. 

* Never hurts to provide a rough 95% confidence interval by using $\pm 2$ MAD_SD.

* We haven't talked much, if at all, about testing or significance. Make sure to point students to this discussion (https://davidkane9.github.io/PPBDS/n-parameters.html#testing) in the book. Most will not have read it, sadly. Make clear to students that my views of testing are somewhat unusual and that a course like Stat 104 or Gov 51 will give them the more traditional view.

* If a group is going too fast, have them provide a nice graphic of the posterior probability distributions for the parameters.


## Scene 2

**Prompt:** Let's make a model with `reg_chg` as the outcome variable and with treatment, poverty, distance and pop_density as the predictors. (Using outcome/predictors is the typical nomenclature in statistics. In Economics, we would refer to dependent/independent variables.)

* Provide the math for this model.

* Estimate the model. Assign the fitted model to `fit_2`. Interpret the important parameters of the model.

**Comments:** 

$$ reg\_chg_i = \beta_0 + \beta_1 local + \beta_2 poverty_i + \\
                \beta_3 distance_i + \beta_4 pop\_density_i +  + \epsilon_i
$$


```{r sc2-a}
fit_2 <- stan_glm(data = week_9,
                  formula = reg_chg ~ treatment + poverty + distance + pop_density,
                  refresh = 0)

print(fit_2, detail = FALSE, digits = 4)
```



* What are the "important" parameters of the model? That is a bit of a philosophical puzzle! Hard to make the case that sigma is important. I also don't really care about the coefficients of poverty, distance and pop_density. Does it really matter that the coefficient for poverty is positive? Not really! Nothing important would change if it were. All we really care about is the coefficient of `treatmentlocal`.

* Polling stations which receive the "local" treatment --- meaning that election officials come there for two days --- have 2% higher rates of increased registration. Because this is an experiment, we believe that this 2% is a causal effect, that `reg_chg` would have been 2% lower in the counterfactual world in which these districts received "control."

* Feel free to discuss interpretations of the other coefficients as well. (Also, challenge groups should try to a couple different versions of the model. What happens to the coefficient of pop_density when you remove poverty?) Make sure to emphasize comparisons, not causal relationships.

* How does the interpretation of this model compare to one in which treatment is the only righthand side variable? This is tricky stuff, which the above discussion elides somewhat. Short version is that, with the other righthand side variables, we are able to give a more precise estimate of the causal effect of `local` since we have "controlled for" pop_density, et al. Of course, if we have randomly assigned treatment, then pop_density and all the righthand side variables should have similar distributions between treated and control. So, including them in the regression should not "matter." But sometimes, by chance, it will! Sometimes, by chance, all the more of the high pop_density communities get the treatment. When that happens, we should "adjust" or "control" for it. Perhaps this entire discussion is too advanced for this class . . .

## Scene 3

**Prompt:** Let's consider a different model. First, create a new variable, `poverty_n`, which is just `poverty` minus the mean of `poverty` then divided by the standard deviation of `poverty`. The "n" is for "normalization."  Second, consider `reg_chg` as a function of `treatment`, `poverty_n` and the interaction between the two.

* Fit the  model and interpret the coefficients. Focus on the coefficient of the interaction term.

* Create a graphic of the posterior probability distribution of the causal effect of `local` treatment in polling stations which have +2 sigma poverty rates. Note that there are two ways to do this. First, we can use a parameter approach. This is what we did in class last week. Second, we can use `posterior_epred()`, which if generally easier since it does the math for us. Confirm that the two approaches give the same answer.



```{r sc3-a}
week_9 <- week_9 %>% 
  mutate(poverty_n = (poverty - mean(poverty))/sd(poverty))


fit_3 <- stan_glm(data = week_9,
                  formula = reg_chg ~ treatment + poverty_n + treatment:poverty_n,
                  refresh = 0)

print(fit_3, detail = FALSE, digits = 3)
```


```{r sc3-parameter-approach}
fit_3 %>% 
  as_tibble() %>% 
  select(treatmentlocal, `treatmentlocal:poverty_n`) %>% 
  mutate(ce = (treatmentlocal * 1) + (`treatmentlocal:poverty_n` * 1 * 2)) %>% 
  
  # 2 above is 
  
  ggplot(aes(ce)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100) +
    labs(title = "Posterior Probability Distribution for Causal Effect of Treatment",
         subtitle = "For local registration at polling stations in poor communities",
         x = "Expected Change in Registration",
         y = "Probability") + 
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme_classic()
```


```{r sc3-epred_posterior-approach}
new_obs <- tibble(treatment = c("local", "control"),
                  poverty_n = 2)

pe <- posterior_epred(fit_3, newdata = new_obs) %>% 
  as_tibble() %>% 
  mutate(ce = `1` - `2`) 

pe %>% 
  ggplot(aes(ce)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100) +
    labs(title = "Posterior Probability Distribution for Causal Effect of Treatment",
         subtitle = "For local registration at polling stations in poor communities",
         x = "Expected Change in Registration",
         y = "Probability") + 
    scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    theme_classic()

```





**Comments:** 


* There are two ways to answer the last question, only the first of which is (currently!) covered in The Primer. In the first, we just use our posterior estimates for the parameters and "plug in" the values for the variables in the case we care about. This is fairly simple because the values for things like `treatmentlocal" are simply +1, so there is not much to plug in. However, plugging in +2 for the value of poverty is still necessary. In my code, I show the +1 explicitly but, of course, in actual code we would not bother with that.

* The second approach uses `posterior_epred()`, which calculates the expected value for a given scenario. Recall that the causal effect is defined as the difference of two potential outcomes. We can use `posterior_epred()` to calculate the posterior predictive distribution for the two possibilities. After that, all we need is subtraction. That is so much easier! Indeed, my plan is to introduce this approach in chapters 7 and 8 when I rewrite this textbook in December. Perhaps I should even drop the coefficient approach completely . . .

* Note the consistency between an "eye-ball" approach of just looking at the model results. The coefficient of `treatmentlocal` is 0.02. The coefficient of the interaction term with `proverty_n` is 0.015. Multiply that by 2 (for the 2 sigma guidance), add it to 0.02 and you get 5%, which is the high point of the posterior.




